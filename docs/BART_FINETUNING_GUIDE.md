# BART Fine-tuning Guide

## ðŸŽ¯ Fine-tuning facebook/bart-large-mnli with Your Data

You're currently using `facebook/bart-large-mnli` for zero-shot classification in your evaluator. Now you can fine-tune this exact same model on your labeled data!

## ðŸ“Š Your Current Setup

**Current Model**: `facebook/bart-large-mnli` (zero-shot)
**Your Dataset**: 1,164 labeled Google Reviews
**Current Performance**: ~53% agreement with LLM labels

## ðŸš€ Fine-tuning Process

### Option 1: Run BART Fine-tuning Script

```bash
python finetune_bart_classifier.py
```

**What this does**:
1. âœ… Loads your labeled dataset
2. âœ… Fine-tunes facebook/bart-large-mnli
3. âœ… Compares zero-shot vs fine-tuned performance
4. âœ… Saves the improved model

**Expected Results**:
- Zero-shot BART: ~53% accuracy
- Fine-tuned BART: ~80-90% accuracy
- **Improvement: +27-37%**

### Option 2: Quick Test (Smaller Sample)

```python
# Test with 200 reviews first
python -c "
from finetune_bart_classifier import BARTReviewClassifierFineTuner

fine_tuner = BARTReviewClassifierFineTuner()
train_dataset, eval_dataset = fine_tuner.load_and_prepare_data('google_reviews_labeled_combined.csv')

# Take smaller sample for quick test
train_small = train_dataset.select(range(200))
eval_small = eval_dataset.select(range(50))

fine_tuner.initialize_model()
model_path = fine_tuner.fine_tune(train_small, eval_small, epochs=2)
print(f'Quick test model saved to: {model_path}')
"
```

## ðŸ”„ Integration with Your Current System

After fine-tuning, you can replace the zero-shot BART in your evaluator:

### Current Code (in google_reviews_evaluator.py):
```python
# Line 32-34
self.bart_classifier = pipeline(
    "zero-shot-classification",
    model="facebook/bart-large-mnli",
```

### Updated Code (after fine-tuning):
```python
# Replace with your fine-tuned model
self.bart_classifier = pipeline(
    "text-classification",  # Changed from zero-shot
    model="path/to/your/fine_tuned_bart_model",
```

## ðŸ“ˆ Expected Performance Improvements

| Model Type | Accuracy | F1-Score | Use Case |
|------------|----------|----------|----------|
| Zero-shot BART | ~53% | ~0.45 | Quick deployment |
| Fine-tuned BART | ~85% | ~0.80 | Production ready |
| Ensemble (LLM + Fine-tuned) | ~90% | ~0.85 | Highest accuracy |

## ðŸ’¡ Pro Tips

1. **Start Small**: Test with 500 reviews first
2. **Monitor Overfitting**: Use validation metrics
3. **Compare Models**: Run the comparison function
4. **Ensemble Approach**: Combine LLM + Fine-tuned BART predictions

## ðŸ›  Next Steps

1. **Run the fine-tuning**: `python finetune_bart_classifier.py`
2. **Compare performance** with built-in comparison
3. **Update your evaluator** to use the fine-tuned model
4. **Enjoy better accuracy**! ðŸŽ‰

The fine-tuned BART will understand your specific review patterns much better than the general zero-shot model!
