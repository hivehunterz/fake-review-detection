# ğŸ›¡ï¸ Review Quality Detection System

A sophisticated machine learning pipeline for detecting review quality using advanced NLP and anomaly detection## âš ï¸ Limitations

### Language Support
- **English Onl## ğŸ“Š Performance Metrics

- **Training Accuracy**: 93.0%
- **Validation Accuracy**: 93.0%
- **Cross-Validation**: 93.6% Â± 4.7%
- **Feature Importance**: p_bad_enhanced_interaction (37.4%)
- **Genuine Detection**: 70% success rate (with optimized thresholds)e system is currently trained and optimized for English reviews only
- **Non-English Content**: Reviews in other languages (Chinese, Malay, Tamil, etc.) may not be accurately classified
- **Mixed Language**: Reviews containing multiple languages may produce unreliable results

### Geographic Context
- **Singapore-Specific Training**: The training data was primarily scraped from Singapore-based businesses and platforms
- **Local Context Advantage**: The model performs better on reviews with Singapore/Southeast Asian context, terminology, and cultural references
- **Global Applicability**: Performance may vary when applied to reviews from other regions due to different:
  - Cultural expressions and review patterns
  - Local business practices and expectations
  - Regional slang and terminology
  - Different spam/fake review tactics

### Recommendations
- **Regional Adaptation**: For optimal performance in other regions, consider retraining with local data
- **Language Extension**: Additional training required for non-English language support
- **Cultural Calibration**: Model thresholds may need adjustment for different cultural contexts

> ğŸ“‹ **For detailed limitations and regional considerations, see [LIMITATIONS.md](LIMITATIONS.md)**

## ğŸ› ï¸ Key Scripts for Testing

### ğŸš€ Universal Review Tester
**File**: `scripts/evaluation/universal_review_tester.py`
**Purpose**: Test ANY CSV file with review data - complete pipeline analysis with detailed predictions
**Usage**:
```bash
python scripts/evaluation/universal_review_tester.py --input your_file.csv --text_column review_text --output results
```
**Features**: 
- âœ… Stage-by-stage analysis (BART â†’ Metadata â†’ Fusion)
- âœ… Detailed predictions with confidence scores
- âœ… Visual emoji indicators (âœ…ğŸŸ¡ğŸŸ ğŸ”´)
- âœ… Comprehensive CSV/JSON reports
- âœ… Automatic visualizations

### ğŸ¯ Demo Dataset
**Location**: `demo/demo_reviews.csv`
**Purpose**: 10 diverse review examples for instant testing
**Content**: Genuine positive/negative, spam, fake enthusiastic, technical reviews
**Usage**: Ready for testing - see `demo/README.md` for instructions

### ğŸ“ Test Your Own Data
**Location**: `demo/` folder
**Guide**: See `HOW_TO_TEST_YOUR_DATA.md` for detailed instructions
**Usage**: Put your CSV file in the `demo/` folder and run analysis
**Supported Format**: CSV with text column (rating, business_name, category optional)

### ğŸ“Š Binary Evaluation System (76.9% Accuracy)
**File**: `scripts/evaluation/binary_evaluation.py`
**Purpose**: Evaluate genuine vs non-genuine classification performance
**Achievement**: 76.9% accuracy, 77.4% ROC AUC for binary classification
**Usage**:
```bash
python scripts/evaluation/binary_evaluation.py
```

### ğŸ¤– Quick Single Review Test
**File**: `scripts/prediction/predict_review_quality.py`
**Purpose**: Test single reviews instantly
**Usage**:
```bash
python scripts/prediction/predict_review_quality.py --text "Your review text here"
```

### ğŸ® Simple Demo
**File**: `demo.py`
**Purpose**: Instant demonstration with pre-loaded examples
**Usage**:
```bash
python demo.py
```

### ğŸ“ˆ Model Training
**File**: `scripts/training/train_all_models.py`
**Purpose**: Train all models from scratch (BART + Metadata + Fusion)
**Usage**:
```bash
python scripts/training/train_all_models.py
```

## ğŸ“‹ Requirements

- Python 3.8+
- PyTorch with CUDA support
- Transformers
- Scikit-learn
- Pandas, NumPy
- NVIDIA GPU (recommended)ues. **No heuristics** - pure ML approach with 93.6% accuracy.

## ğŸš€ Quick Start

### Train Models
```bash
python scripts/training/train_all_models.py
```

### Predict Review Quality
```bash
# Test with demo data
python scripts/evaluation/universal_review_tester.py --input demo/demo_reviews.csv --text_column text

# Test with your own data
python scripts/evaluation/universal_review_tester.py --input your_file.csv --text_column text --output your_results

# Single review test
python scripts/prediction/predict_review_quality.py --text "Amazing food and excellent service!"

# Quick demo
python demo.py
```

## ğŸ—ï¸ Architecture

```
ğŸ“ INPUT â†’ ğŸ¤– BART Classification â†’ ğŸ“Š Metadata Analysis â†’ ğŸ”® Advanced Fusion â†’ ğŸ“‹ OUTPUT
```

### 3 Stages:
1. **ğŸ¤– BART Text Classification**: 7-class fine-tuned model (genuine_positive, genuine_negative, spam, advertisement, irrelevant, fake_rant, inappropriate)
2. **ğŸ“Š Enhanced Metadata Analysis**: ML-based anomaly detection with 88 engineered features
3. **ğŸ”® Advanced Fusion Model**: Gradient boosting combining all signals (93.6% accuracy)

## ğŸ“Š Performance

- **Cross-Validation Accuracy**: 93.6% Â± 4.7%
- **Genuine Detection Rate**: 70% (with optimized thresholds)
- **High-Quality Reviews Found**: 7 out of 10 demo reviews classified as genuine
- **Binary Classification**: 76.9% accuracy for genuine vs non-genuine detection

## ğŸ“ Project Structure

```
fake-review-detection/
â”œâ”€â”€ data/                          # Training and test data
â”‚   â”œâ”€â”€ data_all_training.csv     # Training dataset
â”‚   â””â”€â”€ data_all_test.csv         # Test dataset
â”œâ”€â”€ core/                          # Core ML modules (pure ML - no heuristics)
â”‚   â”œâ”€â”€ stage1_bart/              # BART text classification
â”‚   â”œâ”€â”€ stage2_metadata/          # Metadata anomaly detection
â”‚   â””â”€â”€ fusion/                   # Advanced fusion model
â”œâ”€â”€ scripts/                       # Executable scripts
â”‚   â”œâ”€â”€ training/                 # Model training scripts
â”‚   â”‚   â””â”€â”€ train_all_models.py   # Complete training pipeline
â”‚   â””â”€â”€ prediction/               # Prediction scripts
â”‚       â””â”€â”€ predict_review_quality.py  # Quality prediction pipeline
â”œâ”€â”€ models/                        # Trained models (created after training)
â”‚   â”œâ”€â”€ bart_classifier/          # Fine-tuned BART model
â”‚   â”œâ”€â”€ metadata_analyzer.pkl     # Metadata analyzer
â”‚   â””â”€â”€ fusion_model.pkl          # Advanced fusion model
â”œâ”€â”€ output/                        # Results and logs
â”‚   â”œâ”€â”€ training.log              # Training logs
â”‚   â”œâ”€â”€ prediction.log            # Prediction logs
â”‚   â””â”€â”€ *.csv                     # Result files
â””â”€â”€ demo.py                        # Usage demonstration
```

## ğŸ”§ Output

- **Classifications**: genuine, suspicious, low-quality, high-confidence-spam
- **Routing**: automatic-approval, manual-verification, automatic-rejection
- **Detailed Scores**: BART probabilities, metadata anomaly scores, fusion confidence
- **Enhanced Detection**: 30% genuine review detection with optimized thresholds

## ğŸ¯ Key Achievement

**Advanced ML Pipeline**: Replaced heuristics with pure machine learning - 93.6% accuracy fusion model with 328% improvement in genuine review detection!

## ğŸ“Š Example Results

### High-Quality Reviews Found (30% detection rate):

âœ… **Genuine Review Example:**
```
Text: "Brought my son to shop for fishes and Jeremy was very helpful and informative. 
He provided us with a lot of insights and advice. Really appreciate his great 
customer service and providing us with a pleasant experience. Thank you Jeremy!"

BART Classification: genuine_positive (confidence: 0.977)
P_BAD Risk Score: 0.021
Metadata Anomaly Score: 0.500
Final Prediction: genuine (confidence: 1.000)
Routing: automatic-approval
```

### Prediction Categories:

- âœ… **Genuine** (30%): High-quality, authentic reviews
- ğŸŸ¡ **Suspicious** (47%): Requires manual verification  
- âš ï¸ **Low-Quality** (5%): Poor quality but not spam
- ğŸš« **High-Confidence-Spam** (18%): Automatic rejection

## ğŸ”¬ Technical Details

### Stage 1: BART Text Classification
- Fine-tuned facebook/bart-large-mnli
- 7-class classification with probability distributions
- Computes p_bad scores from spam-related classes
- GPU-accelerated inference

### Stage 2: Enhanced Metadata Analysis
- 88 engineered features (temporal, user, content, business)
- Isolation Forest anomaly detection (200 estimators)
- BART feature integration
- Confidence-weighted scoring

### Stage 3: Advanced Fusion Model
- Gradient Boosting Classifier (n_estimators=200)
- 20 engineered features including interactions
- Multi-factor decision logic with optimized thresholds
- Cross-validated hyperparameters

## ï¿½ Performance Metrics

- **Training Accuracy**: 93.0%
- **Validation Accuracy**: 93.0%
- **Cross-Validation**: 93.6% Â± 4.7%
- **Feature Importance**: p_bad_enhanced_interaction (37.4%)
- **Genuine Detection**: 30% success rate (vs 7% baseline)

## ï¿½ï¸ Development

### Install Dependencies
```bash
pip install -r requirements.txt
```

### Run Demo
```bash
python demo.py
```

### Check Logs
- Training: `output/training.log`
- Prediction: `output/prediction.log`

### Model Details
- BART Model: `models/bart_classifier/`
- Metadata Analyzer: `models/metadata_analyzer.pkl`
- Fusion Model: `models/fusion_model.pkl`

## ï¿½ Requirements

- Python 3.8+
- PyTorch with CUDA support
- Transformers
- Scikit-learn
- Pandas, NumPy
- NVIDIA GPU (recommended)

## ğŸ¯ Use Cases

- **E-commerce Platforms**: Filter fake product reviews
- **Business Listings**: Detect spam restaurant/hotel reviews  
- **Content Moderation**: Identify low-quality user content
- **Market Research**: Extract genuine customer feedback
- **Quality Assurance**: Automated review validation

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Facebook AI for BART model
- Scikit-learn community
- PyTorch team
- Hugging Face Transformers

---

**Made with â¤ï¸ for authentic review detection**

**Version**: 2.0.0 | **Last Updated**: December 2024
