# âš ï¸ System Limitations

## ðŸŒ Language Support

### Current Limitations
- **English Only**: The system is currently trained and optimized for English reviews only
- **Non-English Detection**: Reviews in other languages may be incorrectly classified as spam or low-quality
- **Mixed Language Content**: Reviews containing multiple languages produce unreliable results

### Affected Languages
- Chinese (Simplified/Traditional)
- Malay
- Tamil
- Hindi
- Other Southeast Asian languages
- European languages (French, German, Spanish, etc.)

### Technical Impact
- BART model was fine-tuned on English text only
- Metadata features assume English text patterns
- Sentiment analysis optimized for English expressions

## ðŸŒ Geographic and Cultural Context

### Training Data Specifics
- **Primary Source**: Singapore-based businesses and review platforms
- **Cultural Context**: Southeast Asian business and review practices
- **Local Terminology**: Singapore English, local slang, and cultural references

### Regional Performance Variations

#### âœ… **Best Performance**
- Singapore
- Malaysia
- Southeast Asian English-speaking markets
- Similar cultural and business contexts

#### âš ï¸ **Moderate Performance**
- Other English-speaking regions (US, UK, Australia)
- Different cultural expressions but similar language patterns
- May require threshold adjustments

#### âŒ **Limited Performance**
- Non-English speaking regions
- Significantly different cultural review patterns
- Different spam/fake review tactics and approaches

### Cultural Factors Affecting Accuracy

#### Review Writing Patterns
- **Directness vs. Politeness**: Singapore reviews tend to be more direct compared to other cultures
- **Criticism Style**: Local patterns of expressing dissatisfaction
- **Praise Expression**: Cultural differences in positive feedback

#### Business Context
- **Service Expectations**: Local standards for service quality
- **Industry Practices**: Singapore-specific business practices
- **Consumer Behavior**: Local shopping and review patterns

## ðŸ”§ Technical Limitations

### Model Architecture
- **BART Model**: Pre-trained on general English, fine-tuned on Singapore data
- **Feature Engineering**: Optimized for English text characteristics
- **Anomaly Detection**: Calibrated on local data distributions

### Data Requirements
- **Text Quality**: Assumes reasonable English grammar and structure
- **Review Length**: Optimized for typical review lengths (50-500 words)
- **Metadata Availability**: Better performance with complete metadata

### Performance Boundaries
- **Edge Cases**: Unusual review formats may cause misclassification
- **Domain Shift**: Performance may degrade on significantly different domains
- **Temporal Drift**: Model may need retraining as review patterns evolve

## ðŸ“ˆ Recommendations for Different Use Cases

### For Singapore/SEA Markets
- âœ… Use current model as-is
- âœ… Monitor performance metrics
- âœ… Periodic retraining recommended

### For Other English Markets
- âš ï¸ Test on sample data first
- âš ï¸ Consider threshold calibration
- âš ï¸ Monitor false positive/negative rates
- âš ï¸ Local validation recommended

### For Non-English Markets
- âŒ Not recommended for production use
- ðŸ“š Collect local training data
- ðŸ”„ Retrain models for target language
- ðŸ› ï¸ Adapt feature engineering for local patterns

## ðŸ”® Future Improvements

### Planned Enhancements
1. **Multi-language Support**: Extend to Chinese, Malay, Tamil
2. **Regional Adaptation**: Training on diverse geographic data
3. **Cultural Calibration**: Adjust thresholds for different cultures
4. **Domain Expansion**: Broaden training data across industries

### Development Roadmap
- **Phase 1**: Multi-language text classification
- **Phase 2**: Cross-cultural metadata analysis
- **Phase 3**: Regional model variants
- **Phase 4**: Adaptive threshold learning

## âš¡ Quick Assessment Guide

### Before Implementation
1. **Language Check**: Are your reviews primarily in English?
2. **Geographic Context**: Is your market similar to Singapore/SEA?
3. **Cultural Patterns**: Do review patterns match training data?
4. **Performance Testing**: Run evaluation on sample data

### Red Flags
- âŒ Non-English reviews dominant (>20%)
- âŒ Significantly different cultural context
- âŒ Specialized domain not covered in training
- âŒ Historical data shows different spam patterns

### Green Lights
- âœ… English reviews (>80%)
- âœ… Similar cultural/business context
- âœ… Standard review platforms and formats
- âœ… Comparable spam/fake review patterns

---

**For technical support and regional adaptation inquiries, please refer to the documentation or contact the development team.**
